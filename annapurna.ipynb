{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f98542-763a-4d6e-9e21-ef117397dc5c",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647282675986,
     "user": {
      "displayName": "Analyst sunil",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04665124334899915519"
     },
     "user_tz": 240
    },
    "id": "94f98542-763a-4d6e-9e21-ef117397dc5c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "oBcKza44tpHe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647283075982,
     "user": {
      "displayName": "Analyst sunil",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04665124334899915519"
     },
     "user_tz": 240
    },
    "id": "oBcKza44tpHe",
    "outputId": "b3bc4982-a83d-4f88-ff5a-cffe70c04f83"
   },
   "outputs": [],
   "source": [
    "class Annapurna_Scraper:\n",
    "    '''\n",
    "        Annapurna posts scraper: \n",
    "            It scrapes the posts on the given search_keyword parameter page by page\n",
    "            Scrape up to arround 20 pages at a time; \n",
    "        \n",
    "        How to use:\n",
    "        -- Create an instance of Annapurna_Scraper class\n",
    "        -- While creating instance provide three parameters shown below\n",
    "        -- Call Scrape() method with the instance\n",
    "        -- This method returns data but if save_to_file=True then it also saves to 'scrape.json' \n",
    "            file on the current directory \n",
    "        \n",
    "        >>>> s = Annapurna_Scraper(,page_no=5,search_keyword = 'चुनाव',save_to_file=True)\n",
    "        >>>> data = s.Scrape()\n",
    "    '''\n",
    "    def __init__(self,page_no,search_keyword = 'चुनाव',save_to_file=True):\n",
    "        self.search_keyword = search_keyword\n",
    "        self.page_no = page_no\n",
    "        self.save_to_file = save_to_file\n",
    "        self.data = {}\n",
    "        self.response_data = []\n",
    "        self.file_data = []\n",
    "        self.temp = {}\n",
    "        \n",
    "    def request_data(self,page):\n",
    "        url = f\"https://bg.annapurnapost.com/api/search?title={self.search_keyword}&page={page}\"\n",
    "        header = {\n",
    "            'authority': 'bg.annapurnapost.com',\n",
    "            'content-type': 'application/json',\n",
    "            'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"98\", \"Google Chrome\";v=\"98\"',\n",
    "            'cache-control': 'no-cache',\n",
    "            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36',\n",
    "\n",
    "        }\n",
    "        return requests.get(url,headers=header)\n",
    "    \n",
    "    def fetch_data(self,page):\n",
    "        print(f'Downloading page {page}....')\n",
    "        response = self.request_data(page)\n",
    "        if response.status_code != 200 :\n",
    "            raise Exception('Connection error !!!')\n",
    "        else:\n",
    "            data = response.json()['data']['items']\n",
    "            self.temp['page_no'] = page\n",
    "            self.temp['items'] = data\n",
    "            \n",
    "    def save_data(self):\n",
    "        # self.data= self.file_data + self.response_data \n",
    "        # if self.save_to_file == True:\n",
    "        #     if len(self.response_data) == 0:\n",
    "        #         return self.file_data \n",
    "        #     with open('scrape.json','w') as f:\n",
    "        #         print('Saving ...')\n",
    "        #         json.dump(self.data,f)\n",
    "        #     return self.data\n",
    "        # else:\n",
    "        #     return self.data\n",
    "        with open('scrape.json','w') as f:\n",
    "            json.dump(self.data,f)\n",
    "        return self.data\n",
    "    def Scrape(self):\n",
    "        s_index = 0\n",
    "        try:\n",
    "            with open('scrape.json','r') as f:\n",
    "                data_from_file = json.loads(f.read())\n",
    "            file_flag = True\n",
    "        except:\n",
    "            file_flag = False\n",
    "        for page in range(self.page_no):\n",
    "            self.temp = {}\n",
    "            if file_flag == True:  \n",
    "                for key,value in data_from_file.items():\n",
    "                    if value['page_no'] == page+1:\n",
    "                        print(f'page {page+1} already found in the disk.....')\n",
    "                        page_flag = True\n",
    "                        break\n",
    "                    else:\n",
    "                        page_flag = False\n",
    "                if page_flag == True:\n",
    "                        continue\n",
    "            self.fetch_data(page+1)\n",
    "            self.data[f'search item {page+1}'] = self.temp\n",
    "        return self.save_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07086134",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'page_flag' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m scrape \u001b[38;5;241m=\u001b[39m Annapurna_Scraper(page_no\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,save_to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mscrape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mAnnapurna_Scraper.Scrape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m             page_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpage_flag\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_data(page\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'page_flag' referenced before assignment"
     ]
    }
   ],
   "source": [
    "scrape = Annapurna_Scraper(page_no=2,save_to_file=False)\n",
    "data = scrape.Scrape() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119a0a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 already found in the disk.....\n",
      "page 2 already found in the disk.....\n",
      "page 3 already found in the disk.....\n",
      "page 4 already found in the disk.....\n",
      "page 5 already found in the disk.....\n",
      "page 6 already found in the disk.....\n",
      "page 7 already found in the disk.....\n",
      "Downloading page 8....\n",
      "Downloading page 9....\n",
      "Downloading page 10....\n",
      "Saving ...\n"
     ]
    }
   ],
   "source": [
    "scrape = Annapurna_Scraper(page_no=10,save_to_file=True)\n",
    "data = scrape.Scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Djv3KsbIsyNN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "executionInfo": {
     "elapsed": 21297,
     "status": "ok",
     "timestamp": 1647282785349,
     "user": {
      "displayName": "Analyst sunil",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04665124334899915519"
     },
     "user_tz": 240
    },
    "id": "Djv3KsbIsyNN",
    "outputId": "d04d3318-2e69-48d0-8023-caca0fb7d760"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"analystdk291/annapurna\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/analystdk291/annapurna\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/analystdk291/annapurna'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kQxxm93htDLS",
   "metadata": {
    "id": "kQxxm93htDLS"
   },
   "outputs": [],
   "source": [
    "                try:  \n",
    "                    for file in data_from_file:\n",
    "                        try:\n",
    "                            if (len(file) == 1 and file['page'] == page+1):\n",
    "                                f_index = data_from_file.index(file)\n",
    "                                print(f'page {page+1} already found in the disk.....')\n",
    "                                self.file_data+=data_from_file[s_index:f_index+1]\n",
    "                                s_index = f_index+1\n",
    "                                page_flag = True\n",
    "                                break\n",
    "                            else:\n",
    "                                page_flag = False\n",
    "                        except:\n",
    "                            continue\n",
    "                    if page_flag == True:\n",
    "                        continue\n",
    "                except Exception as e:\n",
    "                    print(e)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "annapurna.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
